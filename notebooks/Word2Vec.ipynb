{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiqc.datasets as QD\n",
    "import qiqc.featurizers as QF\n",
    "import qiqc.preprocessors as QP\n",
    "import qiqc.models as QM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "n_rows = None\n",
    "train_rawdata = QD.QIQCTrainDataset(nrows=n_rows)\n",
    "submit_rawdata = QD.QIQCSubmitDataset(nrows=n_rows)\n",
    "\n",
    "# Build preprocessor\n",
    "preprocessor = QP.PreprocessPipeline(\n",
    "    QP.SentenceNormalizationPipeline(\n",
    "        QP.TypoNormalizer(),\n",
    "    ),\n",
    "    nltk.word_tokenize,\n",
    ")\n",
    "\n",
    "# Tokenize texts\n",
    "train_rawdata.df['tokens'] = train_rawdata.texts.apply(preprocessor)\n",
    "submit_rawdata.df['tokens'] = submit_rawdata.texts.apply(preprocessor)\n",
    "tokens = np.concatenate([\n",
    "    train_rawdata.df.tokens.values,\n",
    "    submit_rawdata.df.tokens.values,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pretrained_vector = QF.load_pretrained_vector('gnews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.54 s, sys: 36 ms, total: 6.58 s\n",
      "Wall time: 6.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = QM.Word2VecEx(size=300, window=3, workers=2)\n",
    "w2v = QF.Word2VecFeaturizer(\n",
    "    model=model,\n",
    "    maxlen=100,\n",
    "    standardize=True,\n",
    ")\n",
    "w2v.model.build_vocab_with_pretraining(\n",
    "    tokens, pretrained_vector, keep_raw_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/default/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/opt/miniconda/envs/default/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('prince', 0.6159993410110474),\n",
       " ('sultan', 0.5864823460578918),\n",
       " ('ruler', 0.5797567367553711),\n",
       " ('princes', 0.5646552443504333),\n",
       " ('throne', 0.5422105193138123),\n",
       " ('royal', 0.5239794254302979),\n",
       " ('kingdom', 0.5210405588150024)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_scratch = deepcopy(w2v)\n",
    "w2v_scratch.model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 12 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_count = 10\n",
    "_w2v = Word2VecEx(size=300, window=3, workers=2)\n",
    "_w2v_scratch = deepcopy(_w2v)\n",
    "_w2v_scratch.build_vocab(tokens, min_count=min_count)\n",
    "_w2v_gnews = deepcopy(_w2v)\n",
    "_w2v_gnews.build_vocab_with_pretraining(tokens, gnews, min_count=min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.6 s, sys: 116 ms, total: 45.7 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_scratch = deepcopy(_w2v_scratch)\n",
    "w2v_scratch.train(tokens, total_examples=len(tokens), epochs=1)\n",
    "models['scratch'] = w2v_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_gnews = deepcopy(_w2v_gnews)\n",
    "models['gnews'] = w2v_gnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.3 s, sys: 140 ms, total: 47.4 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_tokens = None\n",
    "w2v_gnews_ft1000 = deepcopy(_w2v_gnews)\n",
    "w2v_gnews_ft1000.train(tokens[:n_tokens], total_examples=len(tokens[:n_tokens]), epochs=1)\n",
    "models['gnews_ft1000'] = w2v_gnews_ft1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 128 ms, total: 47 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v_gnews_ft = deepcopy(_w2v_gnews)\n",
    "w2v_gnews_ft.train(tokens, total_examples=len(tokens), epochs=1)\n",
    "models['gnews_ft'] = w2v_gnews_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 2.19 s, total: 1min 34s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_tokens = None\n",
    "w2v_gnews_ft_freeze = deepcopy(_w2v_gnews)\n",
    "with w2v_gnews_ft_freeze.freeze_pretrained_vector():\n",
    "    w2v_gnews_ft_freeze.train(tokens[:n_tokens], total_examples=len(tokens[:n_tokens]), epochs=1)\n",
    "models['gnews_ft_freeze'] = w2v_gnews_ft_freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/default/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scratch</th>\n",
       "      <th>gnews</th>\n",
       "      <th>gnews_ft1000</th>\n",
       "      <th>gnews_ft</th>\n",
       "      <th>gnews_ft_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>France</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>French</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>Versailles</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>London</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>Brussels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charleston</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>1980s</td>\n",
       "      <td>1980s</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scratch       gnews gnews_ft1000   gnews_ft gnews_ft_freeze\n",
       "0    Maryland      France       London     London          London\n",
       "1     Atlanta      French       France     France          France\n",
       "2     Chicago    Brussels       Berlin     Berlin          Berlin\n",
       "3      Dallas  Versailles    Amsterdam  Amsterdam       Amsterdam\n",
       "4   Manhattan      Madrid         Rome       Rome            Rome\n",
       "5      Boston        Rome        Spain      Spain           Spain\n",
       "6     Georgia      Berlin        Italy      Italy           Italy\n",
       "7     Morocco   Marseille      Morocco    Morocco         Morocco\n",
       "8     Arizona      London     Brussels   Brussels        Brussels\n",
       "9  Charleston      Vienna        1980s      1980s           1980s"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'Paris'\n",
    "pd.DataFrame(dict([(k, [w[0] for w in m.wv.most_similar(word)]) for k, m in models.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scratch</th>\n",
       "      <th>gnews</th>\n",
       "      <th>gnews_ft1000</th>\n",
       "      <th>gnews_ft</th>\n",
       "      <th>gnews_ft_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70s</td>\n",
       "      <td>Forces</td>\n",
       "      <td>70s</td>\n",
       "      <td>70s</td>\n",
       "      <td>70s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90s</td>\n",
       "      <td>Liberation</td>\n",
       "      <td>1997</td>\n",
       "      <td>1980s</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand</td>\n",
       "      <td>Gays</td>\n",
       "      <td>1980s</td>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>PKK</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>Homosexual</td>\n",
       "      <td>1930s</td>\n",
       "      <td>1930s</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Warsaw</td>\n",
       "      <td>Gauntlet</td>\n",
       "      <td>90s</td>\n",
       "      <td>2003</td>\n",
       "      <td>90s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pluto</td>\n",
       "      <td>Transform</td>\n",
       "      <td>2002</td>\n",
       "      <td>90s</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Labour</td>\n",
       "      <td>2003</td>\n",
       "      <td>2002</td>\n",
       "      <td>1800s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997</td>\n",
       "      <td>Nationalists</td>\n",
       "      <td>1800s</td>\n",
       "      <td>1800s</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Future</td>\n",
       "      <td>1942</td>\n",
       "      <td>1942</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        scratch         gnews gnews_ft1000 gnews_ft gnews_ft_freeze\n",
       "0           70s        Forces          70s      70s             70s\n",
       "1           90s    Liberation         1997    1980s           1980s\n",
       "2         Grand          Gays        1980s     1997            1997\n",
       "3     Tennessee           PKK         1994     1994            1994\n",
       "4          1988    Homosexual        1930s    1930s           1930s\n",
       "5        Warsaw      Gauntlet          90s     2003             90s\n",
       "6         Pluto     Transform         2002      90s            2002\n",
       "7     Louisiana        Labour         2003     2002           1800s\n",
       "8          1997  Nationalists        1800s    1800s            2003\n",
       "9  Philadelphia        Future         1942     1942            1942"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = '1960s'\n",
    "pd.DataFrame(dict([(k, [w[0] for w in m.wv.most_similar(word)]) for k, m in models.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scratch</th>\n",
       "      <th>gnews</th>\n",
       "      <th>gnews_ft1000</th>\n",
       "      <th>gnews_ft</th>\n",
       "      <th>gnews_ft_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comments</td>\n",
       "      <td>Squarespace</td>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instagram</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Snapchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answers</td>\n",
       "      <td>reddit</td>\n",
       "      <td>answers</td>\n",
       "      <td>answers</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>questions</td>\n",
       "      <td>DuckDuckGo</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>answer</td>\n",
       "      <td>answer</td>\n",
       "      <td>answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>questions</td>\n",
       "      <td>questions</td>\n",
       "      <td>questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>question</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>comments</td>\n",
       "      <td>comments</td>\n",
       "      <td>comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comment</td>\n",
       "      <td>Wordpress</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>Tumblr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     scratch        gnews gnews_ft1000   gnews_ft gnews_ft_freeze\n",
       "0       here       Tumblr     Facebook   Facebook        Facebook\n",
       "1   Facebook    Instagram    Instagram  Instagram       Instagram\n",
       "2   comments  Squarespace         here       here            here\n",
       "3  Instagram       Reddit     Snapchat   Snapchat        Snapchat\n",
       "4    answers       reddit      answers    answers         Twitter\n",
       "5  questions   DuckDuckGo      Twitter    Twitter         answers\n",
       "6   Snapchat     Facebook       answer     answer          answer\n",
       "7    Twitter         Yelp    questions  questions       questions\n",
       "8   question     LinkedIn     comments   comments        comments\n",
       "9    comment    Wordpress       Tumblr     Tumblr          Tumblr"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'Quora'\n",
    "pd.DataFrame(dict([(k, [w[0] for w in m.wv.most_similar(word)]) for k, m in models.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseWordEmbeddingsModelEx:\n",
    "    def hoge(self):\n",
    "        print('hoge')\n",
    "        \n",
    "    def _clear_post_train(self):\n",
    "        print('fuga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecEx2(BaseWordEmbeddingsModelEx, Word2Vec):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = Word2VecEx2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 'a'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1, *{'a': 1}.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
