batchsize: 512
batchsize_valid: 1024
dataset_seed: 0
device: 0
epochs: 5
featurizer:
  n_finetune: 1
  pretrain: gnews
  model: word2vec
  train:
    alpha: 1e-4
    min_count: 10
    size: 300
    window: 3
    workers: 2
model:
  embed:
    n_embed: 300
    freeze_embed: True
    position: true
    n_hidden: 128
    hidden_bn: False
  encoder:
    dropout: 0.2
    n_hidden: 128
    n_layers: 2
    attn_heads: 4
    out_scale: 1
    aggregator: max
  mlp:
    bn: True
    n_layers: 2
    n_hidden: 128
model_seed: 0
n_rows: null
optimizer:
  lr: 1e-3
outdir: experiments/models/bilstm/baseline
