batchsize: 512
batchsize_valid: 1024
seed: 0
epochs: 5
maxlen: 72

preprocessors:
  - lower
  - punct
  - number
  - hengzheng_mispell
  - keras
tokenizer: space
embedding:
  src:
    - glove
    - paragram
  model:
    word2vec
  params:
    size: 300
  standardize:
    False

optimizer:
  lr: 1e-3
