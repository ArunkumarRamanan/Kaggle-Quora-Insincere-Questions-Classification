batchsize: 512
batchsize_valid: 1024
seed: 0
epochs: 5
maxlen: 72

vocab:
  max_size: 95000
  min_count: 5
preprocessors:
  - lower
  - punct
  - number
  - hengzheng_mispell
  - keras
tokenizer: space
embedding:
  finetune:
    True
  src:
    - glove
    - paragram
  model:
    word2vec
  params:
    alpha: 1e-4
    size: 300
  standardize:
    False

optimizer:
  lr: 1e-3
ensembler: avg
