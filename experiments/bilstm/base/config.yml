batchsize: 512
batchsize_valid: 1024
seed: 0
epochs: 5
maxlen: 72
logging: True
pos_weight: 1.

vocab:
  max_size:
  min_count: 5
preprocessors:
  - lower
  - misspell
  - punct
  - number+underscore
tokenizer: space
embedding:
  add_los:
    True
  finetune:
    False
  src:
    - glove
    - paragram
  model:
    word2vec
  params:
    alpha: 1e-4
    size: 300
    min_count: 0
  standardize:
    False

optimizer:
  name: adam
  params:
    lr: 0.001
  scheduler:
    ReduceLROnPlateau
model:
  embed:
    n_embed: 300
    freeze_embed: True
    position: false
    n_hidden: 0
    hidden_bn: False
    dropout: 0.2
  encoder:
    name: lstm
    bidirectional: True
    dropout: 0.2
    n_input: 300
    n_hidden: 128
    n_layers: 2
    out_scale: 2
    aggregator: max
  mlp:
    bn0: True
    bn: True
    dropout0: 0
    dropout: 0
    n_layers: 2
    n_hidden: 128
ensembler:
  model: avg
  test_size: 0.1
  epochs: 1
  params:
    bn: True
    n_layers: 2
    n_hidden: 128
